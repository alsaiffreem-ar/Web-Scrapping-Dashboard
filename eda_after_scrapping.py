# -*- coding: utf-8 -*-
"""EDA after scrapping

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yl0x5fjE2os5dKt79fQ9T2zzdlw40AMP

# EDA - Data Cleaning
"""

# Install Plotly (usually pre-installed in Colab)
!pip install plotly --quiet

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# Read the CSV exported from your scraper notebook
df = pd.read_csv("/content/products.csv")
# Quick look at the data
df.head(5)

df.shape

"""# (755, 12)"""

df.dtypes

"""# Cleaning"""

# Check for duplicates
dup = df.duplicated().sum()
dup

import pandas as pd

# Convert Price to integer
df["Price"] = (
    df["Price"]
    .astype(str)
    .str.replace("£", "", regex=False)
)
df["Price"] = pd.to_numeric(df["Price"], errors="coerce").fillna(0).astype(int)

# Ensure Stock Quantity is integer
df["Stock Quantity"] = pd.to_numeric(df["Stock Quantity"], errors="coerce").fillna(0).astype(int)

# Convert Weight to numeric (float)
df['Weight'] = (
    df['Weight']
    .astype(str)
    .str.extract(r'([\d.]+)')  # extract the numeric part
)
df['Weight'] = pd.to_numeric(df['Weight'], errors="coerce").fillna(0)


# Get all unique Categories across the DataFrame
unique_categories = set(cat for row in df['Categories'] for cat in row)

# Get all unique Tags across the DataFrame
unique_tags = set(tag for row in df['Tags'] for tag in row)

print("Unique Categories:", unique_categories)
print("Unique Tags:", unique_tags)

df.dtypes

df.head(10)

df.isnull().sum()

# Drop rows with null Dimensions
df = df.dropna(subset=["Dimensions"])

# Check
df.isnull().sum()

df.dtypes

"""# (738, 12) After cleaning"""

#after adding 4 columns and droping duplicate
df.shape

# Save cleaned data
df.to_csv("/content/cleaned_web_scarpe.csv", index=False)

"""# Visualization"""

import pandas as pd
import plotly.express as px

# Load your data
df = pd.read_csv("/content/cleaned_web_scarpe.csv")

# Automatically pick only numeric columns
num_cols = df.select_dtypes(include=['int64', 'float64']).columns

# 4 Visuals
# Loop through numeric columns and show bar charts
for col in num_cols:
    fig = px.bar(
        x=df.index,           # x-axis as row index
        y=df[col],            # y-axis is the numeric column
        title=f"Bar Chart of {col}",
        labels={"x": "Row Index", "y": col}
    )
    fig.show()

"""# Streamlit Dashboard"""

!pip install streamlit seaborn matplotlib pandas
!pip install pyngrok

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# Commented out IPython magic to ensure Python compatibility.
# %%writefile scrapedashboard.py
# import streamlit as st
# import pandas as pd
# import plotly.express as px
# import plotly.graph_objects as go
# from plotly.subplots import make_subplots
# 
# # ----------------------------------------------------
# # Page settings
# st.set_page_config(page_title="Web Scrape Dashboard", layout="wide")
# 
# # Apply dark theme CSS for body and sidebar
# st.markdown("""
# <style>
# body { background-color: #0A0A0A; color: #E0E1DD; }
# .sidebar .sidebar-content { background-color: #0D1B2A; color: #E0E1DD; }
# </style>
# """, unsafe_allow_html=True)
# 
# # ----------------------------------------------------
# # Load dataset
# df = pd.read_csv("/content/cleaned_web_scarpe.csv")
# 
# # ----------------------------------------------------
# # Sidebar filters
# st.sidebar.header("Filters")
# 
# # Sidebar description
# st.sidebar.markdown(
#     """
#     **About the Data**
#     This dashboard displays products scraped from the website.
#     - Title, Image URL, Price,
#     - Short Description,Stock Status, Stock Quantity
#     - SKU, Categories,	Tags,
#     - Weight,	Dimensions,	Reviews.
#     """
# )
# 
# 
# 
# # Price range slider
# min_price, max_price = int(df["Price"].min()), int(df["Price"].max())
# price_range = st.sidebar.slider(
#     "Price Range (£)",
#     min_price,
#     max_price,
#     (min_price, max_price)
# )
# 
# # Weight range slider
# min_weight, max_weight = int(df["Weight"].min()), int(df["Weight"].max())
# weight_range = st.sidebar.slider(
#     "Weight Range (kg)",
#     min_weight,
#     max_weight,
#     (min_weight, max_weight)
# )
# 
# 
# # ----------------------------------------------------
# # Apply filters to dataframe
# filtered_df = df.copy()
# 
# 
# 
# # Filter by Price and Weight range
# filtered_df = filtered_df[
#     (filtered_df["Price"] >= price_range[0]) & (filtered_df["Price"] <= price_range[1]) &
#     (filtered_df["Weight"] >= weight_range[0]) & (filtered_df["Weight"] <= weight_range[1])
# ]
# 
# 
# # Display dashboard title
# st.title("Web Scrape Dashboard")
# 
# 
# 
# # KPI Metrics
# # Display total products, average price, max price, and min price
# col1, col2, col3, col4 = st.columns(4)
# col1.metric("Total Products", f"{filtered_df.shape[0]}")
# col2.metric("Average Price (£)", f"{filtered_df['Price'].mean():.2f}")
# col3.metric("Max Price (£)", f"{filtered_df['Price'].max():.2f}")
# col4.metric("Min Price (£)", f"{filtered_df['Price'].min():.2f}")
# 
# 
# 
# # Visual Insights
# st.subheader("Visual Insights")
# 
# #------------------------------------------------------------------------------------
# 
# # 1. Average Price by Tag
# # Bar Chart
# tag_avg_price = df.explode('Tags').groupby('Tags')['Price'].mean().sort_values(ascending=False).reset_index()
# fig_tag_price = px.bar(tag_avg_price, x='Tags', y='Price',
#                        color='Price',
#                        color_continuous_scale='Tealgrn',
#                        title="Average Price by Tag")
# st.plotly_chart(fig_tag_price, use_container_width=True)
# 
# 
# 
# # 2. Stock Quantity per Tag
# # Bar Chart
# tag_stock_qty = df.explode('Tags').groupby('Tags')['Stock Quantity'].sum().sort_values(ascending=False).reset_index()
# fig_tag_stock = px.bar(tag_stock_qty, x='Tags', y='Stock Quantity',
#                        color='Stock Quantity',
#                        color_continuous_scale='Tealgrn',
#                        title="Stock Quantity per Tag")
# st.plotly_chart(fig_tag_stock, use_container_width=True)
# 
# 
# # 3. Price Distribution Histogram (Filtered Products)
# # Histogram
# fig_price_hist = px.histogram(
#     filtered_df,
#     x='Price',
#     nbins=20,
#     color_discrete_sequence=['#1abc9c'],  # single custom color
#     title="Price Distribution (Filtered Products)"
# )
# st.plotly_chart(fig_price_hist, use_container_width=True)
# 
# 
# # 4. Top 10 Heaviest Products
# # Bar Chart
# top_weight = filtered_df.sort_values('Weight', ascending=False).head(10)
# fig_heavy = px.bar(top_weight, x='Title', y='Weight', color='Price',
#                    color_continuous_scale='Tealgrn',
#                    title="Top 10 Heaviest Products")
# st.plotly_chart(fig_heavy, use_container_width=True)
# 
# 
# 
# # 5. Top 10 Categories by Average Price
# # Bar Chart
# cat_avg_price = df.explode('Categories').groupby('Categories')['Price'].mean().sort_values(ascending=False).head(10).reset_index()
# fig_cat_price = px.bar(cat_avg_price, x='Categories', y='Price',
#                        color='Price',
#                        color_continuous_scale='Tealgrn',
#                        title="Top 10 Categories by Average Price")
# st.plotly_chart(fig_cat_price, use_container_width=True)
# 
# 
# 
# # 6. Top 10 Categories by Stock Quantity
# # Bar Chart
# cat_stock = df.explode('Categories').groupby('Categories')['Stock Quantity'].sum().sort_values(ascending=False).head(10).reset_index()
# fig_cat_stock = px.bar(cat_stock, x='Categories', y='Stock Quantity',
#                        color='Stock Quantity',
#                        color_continuous_scale='Tealgrn',
#                        title="Top 10 Categories by Stock Quantity")
# st.plotly_chart(fig_cat_stock, use_container_width=True)
# 
# 
#

#Setup the ngrok authentication in Colab
# ngrok is a tool that creates a secure public URL for your local server or app.
!ngrok authtoken 32bJAa5wxdXtCSD0RliIWd7s5qc_3vz2MP1M2jz5ZCyKdse2s

# Import the pyngrok library to manage ngrok tunnels in Python
from pyngrok import ngrok

# Kill any previous tunnels
ngrok.kill()

# Start a new ngrok tunnel on port 8501 (default Streamlit port)
url = ngrok.connect(8501)

# Print the public URL to open in browser
print(f"Streamlit app is live at: {url}")

# Run Streamlit in the background
!streamlit run /content/scrapedashboard.py &>/dev/null &