# -*- coding: utf-8 -*-
"""Web scrapping week3 day 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n46P-HzTGRHBH0ke9kuuobGi_3lOAR9F

# Web Scrapping
week3 day 2 - 22/09/2025
"""

# Imports
import requests
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt

# %matplotlib inline

# Scrapeme web page
scrapeme = 'https://scrapeme.live/shop/'

# Use requests to retrieve data from a given URL
scrapeme_response = requests.get(scrapeme)
scrapeme_response

# Parse the whole HTML page using BeautifulSoup
scrapeme_soup = BeautifulSoup(scrapeme_response.text, 'html.parser')
print(scrapeme_soup.prettify())

scrapeme_soup.title

Product_list_= scrapeme_soup.find('ul', {'class':'products columns-4'})
Product_list_

Page_list= scrapeme_soup.find('ul', {'class':'page-numbers'})
Page_list

Page_links = Page_list.find_all('a')

Page_links

# list of all page URLs
Page_href_list = []
for i in range(1, 49):
    Page_href_list.append("https://scrapeme.live/shop/page/" + str(i) + "/")
print(Page_href_list)
len(Page_href_list)

import requests

# Loop through each page URL in your list
for page_link in Page_href_list:
    # Send an HTTP GET request to the page
    # 'verify=False' disables SSL certificate verification (useful if the certificate is expired or invalid)
    page_respond = requests.get(page_link, verify=False)

    # Print the page URL and its HTTP response status code
    # A status code of 200 means the request was successful
    print(f"URL: {page_link} | Status Code: {page_respond.status_code}")

import requests
from bs4 import BeautifulSoup

# list of all page URLs
Page_href_list = [f"https://scrapeme.live/shop/page/{i}/" for i in range(1, 49)]

all_product_urls = []

for page_link in Page_href_list:
    # Send request to each page (should return 200 if successful)
    response = requests.get(page_link, verify=False)

    # Parse the page HTML (يعني HTML)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find all product links
    products = soup.find('ul', class_='products')
    if products:
        for a_tag in products.find_all('a', class_='woocommerce-LoopProduct-link'):
            product_url = a_tag['href']
            all_product_urls.append(product_url)

# Print all product URLs
for url in all_product_urls:
    print(url)

len(all_product_urls)

import requests
from bs4 import BeautifulSoup


# Lists to store each type of info
titles = []
images = []
prices = []
short_descriptions = []
stock_statuses = []
stock_quantities = []
skus = []
categories_list = []
tags_list = []
weights = []
dimensions = []
reviews_list = []

# Loop through all product URLs
for url in all_product_urls:
    # Request the product page 200
    response = requests.get(url, verify=False, timeout=10)

    # Print the URL and status code for monitoring 200
    print(f"URL: {url} | Status Code: {response.status_code}")

    # Parse HTML content
    soup = BeautifulSoup(response.text, 'html.parser')


    # Product Title
    title_tag = soup.find('h1', class_='product_title entry-title')
    title = title_tag.text.strip() if title_tag else ""  # Use empty string if not found
    titles.append(title)

    # Product Image
    img_tag = soup.find('figure', class_='woocommerce-product-gallery__wrapper')
    if img_tag:
        first_img = img_tag.find('img')
        image_url = first_img['src'] if first_img else ""
    else:
        image_url = ""
    images.append(image_url)

    # Product Price
    price_tag = soup.find('p', class_='price')
    price = price_tag.text.strip() if price_tag else ""
    prices.append(price)

    # Short Description
    short_desc_tag = soup.find('div', class_='woocommerce-product-details__short-description')
    short_description = short_desc_tag.text.strip() if short_desc_tag else ""
    short_descriptions.append(short_description)

    # Stock Status & Quantity
    stock_status = "Unknown"
    stock_quantity = ""

    stock_tag = soup.find("p", class_="stock")
    if stock_tag:
        raw_stock = stock_tag.get_text(strip=True)
        # Check for typical WooCommerce phrasing
        if "in stock" in raw_stock.lower():
            stock_status = "In stock"
            # Try to pull a number if present (e.g., "45 in stock" or "In stock (23)")
            import re
            match = re.search(r"(\d+)", raw_stock)
            if match:
                stock_quantity = int(match.group(1))
        elif "out of stock" in raw_stock.lower():
            stock_status = "Out of stock"
            stock_quantity = 0
    stock_statuses.append(stock_status)
    stock_quantities.append(stock_quantity)

    # Product Meta (SKU, Categories, Tags)
    sku_tag = soup.find('span', class_='sku')
    sku = sku_tag.text.strip() if sku_tag else ""
    skus.append(sku)

    categories_tag = soup.find('span', class_='posted_in')
    categories = categories_tag.text.strip() if categories_tag else ""
    categories_list.append(categories)

    tags_tag = soup.find('span', class_='tagged_as')
    tags = tags_tag.text.strip() if tags_tag else ""
    tags_list.append(tags)

    # Weight
    weight_tag = soup.find('td', class_='product_weight')
    weight = weight_tag.text.strip() if weight_tag else ""
    weights.append(weight)

    # Dimensions
    dimensions_tag = soup.find('td', class_='product_dimensions')
    dimension = dimensions_tag.text.strip() if dimensions_tag else ""
    dimensions.append(dimension)

    # Reviews
    reviews_div = soup.find('div', class_='woocommerce-Reviews')
    reviews_text = reviews_div.text.strip() if reviews_div else ""
    reviews_list.append(reviews_text)

# Check the first few entries
print(titles[:5])
print(images[:5])
print(prices[:5])
print(short_descriptions[:5])
print(stock_statuses[:5])
print(stock_quantities[:5])
print(skus[:5])
print(categories_list[:5])
print(tags_list[:5])
print(weights[:5])
print(dimensions[:5])
print(reviews_list[:5])

"""# DataFrame"""

import pandas as pd

# Create a dictionary with all the lists, including new fields
data = {
    "Title": titles,
    "Image URL": images,
    "Price": prices,
    "Short Description": short_descriptions,
    "Stock Status": stock_statuses,
    "Stock Quantity": stock_quantities,
    "SKU": skus,
    "Categories": categories_list,
    "Tags": tags_list,
    "Weight": weights,                # Added
    "Dimensions": dimensions,         # Added
    "Reviews": reviews_list           # Added
}

# Create a DataFrame
df = pd.DataFrame(data)

# Preview the first 5 rows
print(df.head())

# Save to CSV
df.to_csv("products.csv", index=False)